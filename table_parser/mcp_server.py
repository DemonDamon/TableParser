"""
TableParser MCPæœåŠ¡å™¨

åŸºäºFastMCPå®ç°çš„MCPå·¥å…·æœåŠ¡å™¨ï¼Œæ”¯æŒAIæ™ºèƒ½ä½“ç›´æ¥è°ƒç”¨
"""

import base64
import logging
import sys
from pathlib import Path
from typing import Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

# å¤„ç†ç›¸å¯¹å¯¼å…¥å’Œç›´æ¥è¿è¡Œçš„å…¼å®¹æ€§
if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæ—¶ï¼Œæ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from table_parser.parser import TableParser
    from table_parser.types import ComplexityScore
else:
    # ä½œä¸ºæ¨¡å—å¯¼å…¥æ—¶ï¼Œä½¿ç”¨ç›¸å¯¹å¯¼å…¥
    from .parser import TableParser
    from .types import ComplexityScore

from fastmcp import FastMCP

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åˆ›å»ºMCPæœåŠ¡å™¨
mcp = FastMCP("TableParser")

# åˆå§‹åŒ–è§£æå™¨
parser = TableParser()

# å®‰å…¨é…ç½®
ALLOWED_PATHS = [
    "/data",
    "/reports",
    "/tmp",
    "/Users",  # macOS
    "/home",   # Linux
]
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB


def validate_file_path(file_path: str) -> bool:
    """éªŒè¯æ–‡ä»¶è·¯å¾„æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•ä¸­"""
    try:
        abs_path = Path(file_path).resolve()
        return any(
            str(abs_path).startswith(allowed)
            for allowed in ALLOWED_PATHS
        )
    except Exception:
        return False


def validate_file_size(file_path: str) -> bool:
    """éªŒè¯æ–‡ä»¶å¤§å°"""
    try:
        return Path(file_path).stat().st_size <= MAX_FILE_SIZE
    except Exception:
        return False


def generate_recommendation(score: ComplexityScore) -> str:
    """ç”Ÿæˆäººç±»å¯è¯»çš„å»ºè®®"""
    if score.level == "simple":
        return (
            f"è¿™æ˜¯ä¸€ä¸ªç®€å•è¡¨æ ¼ï¼ˆå¾—åˆ†{score.total_score:.1f}ï¼‰ï¼Œ"
            f"æ¨èä½¿ç”¨Markdownæ ¼å¼ï¼Œæ˜“äºé˜…è¯»å’Œç¼–è¾‘ã€‚"
        )
    elif score.level == "medium":
        return (
            f"è¿™æ˜¯ä¸€ä¸ªä¸­ç­‰å¤æ‚åº¦è¡¨æ ¼ï¼ˆå¾—åˆ†{score.total_score:.1f}ï¼‰ï¼Œ"
            f"å¯ä»¥ä½¿ç”¨Markdownï¼Œä½†éƒ¨åˆ†ç»“æ„å¯èƒ½æ— æ³•å®Œç¾ä¿ç•™ã€‚"
            f"å¦‚éœ€ç²¾ç¡®è¿˜åŸï¼Œè¯·ä½¿ç”¨HTMLæ ¼å¼ã€‚"
        )
    else:
        return (
            f"è¿™æ˜¯ä¸€ä¸ªå¤æ‚è¡¨æ ¼ï¼ˆå¾—åˆ†{score.total_score:.1f}ï¼‰ï¼Œ"
            f"åŒ…å«åˆå¹¶å•å…ƒæ ¼æˆ–å¤šçº§è¡¨å¤´ï¼Œå¼ºçƒˆæ¨èä½¿ç”¨HTMLæ ¼å¼ä»¥ä¿ç•™å®Œæ•´ç»“æ„ã€‚"
        )


@mcp.tool()
def parse_table(
    file_path: Optional[str] = None,
    file_content_base64: Optional[str] = None,
    output_format: str = "auto",
    chunk_rows: int = 256,
    clean_illegal_chars: bool = True,
    output_path: Optional[str] = None,
    extract_images: bool = True,
    images_dir: Optional[str] = None
) -> dict:
    """
    è§£æExcelæˆ–CSVè¡¨æ ¼æ–‡ä»¶
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        file_content_base64: Base64ç¼–ç çš„æ–‡ä»¶å†…å®¹ï¼ˆfile_pathä¸å­˜åœ¨æ—¶ä½¿ç”¨ï¼‰
        output_format: è¾“å‡ºæ ¼å¼ (auto/markdown/html)
        chunk_rows: HTMLåˆ†å—è¡Œæ•°
        clean_illegal_chars: æ˜¯å¦æ¸…ç†éæ³•å­—ç¬¦
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            - å¦‚æœæä¾›ï¼šä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
            - å¦‚æœä¸æä¾›ä¸”æœ‰file_pathï¼šé»˜è®¤ä¿å­˜åˆ°ExcelåŒç›®å½•ï¼ˆè‡ªåŠ¨èŠ‚çœtokenï¼‰
            - å¦‚æœä¸æä¾›ä¸”æ˜¯Base64è¾“å…¥ï¼šè¿”å›å®Œæ•´å†…å®¹
        extract_images: æ˜¯å¦æå–Excelä¸­çš„å›¾ç‰‡ï¼ˆé»˜è®¤Trueï¼‰
        images_dir: å›¾ç‰‡ä¿å­˜ç›®å½•ï¼ˆå¯é€‰ï¼‰
            - å¦‚æœæä¾›ï¼šä¿å­˜åˆ°æŒ‡å®šç›®å½•
            - å¦‚æœä¸æä¾›ï¼šè‡ªåŠ¨ä¿å­˜åˆ°ExcelåŒç›®å½•çš„imagesæ–‡ä»¶å¤¹
        
    Returns:
        è§£æç»“æœå­—å…¸ã€‚ä¿å­˜æ–‡ä»¶æ—¶åªè¿”å›å…ƒæ•°æ®ï¼Œä¸è¿”å›å®Œæ•´å†…å®¹ï¼ˆå¤§å¹…èŠ‚çœtokenï¼‰
    
    Examples:
        # ç¤ºä¾‹1ï¼šè‡ªåŠ¨ä¿å­˜ï¼ˆæ¨èï¼Œè‡ªåŠ¨èŠ‚çœtokenï¼‰
        # ä¼šä¿å­˜åˆ° /path/to/data.html æˆ– data.mdï¼ˆå–å†³äºå¤æ‚åº¦ï¼‰
        result = parse_table(file_path="/path/to/data.xlsx")
        
        # ç¤ºä¾‹2ï¼šæŒ‡å®šä¿å­˜è·¯å¾„
        result = parse_table(
            file_path="/path/to/data.xlsx",
            output_path="/another/path/result.html"
        )
        
        # ç¤ºä¾‹3ï¼šBase64è¾“å…¥ï¼ˆè¿”å›å®Œæ•´å†…å®¹ï¼‰
        with open("data.xlsx", "rb") as f:
            content_b64 = base64.b64encode(f.read()).decode()
        result = parse_table(file_content_base64=content_b64)
        
        # ç¤ºä¾‹4ï¼šå¼ºåˆ¶HTMLæ ¼å¼
        result = parse_table(
            file_path="/path/to/data.xlsx",
            output_format="html"
        )
    """
    try:
        # ç¡®å®šè¾“å…¥æº
        if file_path:
            # å®‰å…¨éªŒè¯
            if not validate_file_path(file_path):
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶è·¯å¾„ä¸åœ¨å…è®¸çš„ç›®å½•ä¸­: {file_path}"
                }
            
            if not validate_file_size(file_path):
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶è¿‡å¤§ï¼ˆè¶…è¿‡50MBï¼‰: {file_path}"
                }
            
            input_data = file_path
            logger.info(f"è§£ææ–‡ä»¶: {file_path}")
            
        elif file_content_base64:
            try:
                input_data = base64.b64decode(file_content_base64)
                logger.info(f"è§£æBase64å†…å®¹ ({len(input_data)} bytes)")
            except Exception as e:
                return {
                    "success": False,
                    "error": f"Base64è§£ç å¤±è´¥: {e}"
                }
        else:
            return {
                "success": False,
                "error": "å¿…é¡»æä¾› file_path æˆ– file_content_base64"
            }
        
        # æ‰§è¡Œè§£æ
        result = parser.parse(
            input_data,
            output_format=output_format,
            chunk_rows=chunk_rows,
            clean_illegal_chars=clean_illegal_chars,
            extract_images=extract_images,
            images_dir=images_dir
        )
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        # 1. å¦‚æœæ˜ç¡®æä¾›äº† output_pathï¼Œä½¿ç”¨å®ƒ
        # 2. å¦‚æœæ²¡æœ‰æä¾› output_pathï¼Œä½†æœ‰ file_pathï¼Œé»˜è®¤ä¿å­˜åˆ°åŒç›®å½•
        # 3. å¦‚æœéƒ½æ²¡æœ‰ï¼ˆBase64è¾“å…¥ï¼‰ï¼Œåˆ™è¿”å›å®Œæ•´å†…å®¹
        actual_output_path = output_path
        
        if not actual_output_path and file_path:
            # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºè·¯å¾„ï¼šåŒç›®å½•ï¼Œæ‰©å±•åæ”¹ä¸º .html æˆ– .md
            source_file = Path(file_path)
            if result.output_format == "markdown":
                actual_output_path = str(source_file.with_suffix('.md'))
            else:  # HTML
                actual_output_path = str(source_file.with_suffix('.html'))
            logger.info(f"æœªæŒ‡å®šè¾“å‡ºè·¯å¾„ï¼Œè‡ªåŠ¨ä¿å­˜åˆ°: {actual_output_path}")
        
        # å¦‚æœæœ‰è¾“å‡ºè·¯å¾„ï¼ˆæ˜ç¡®æŒ‡å®šæˆ–è‡ªåŠ¨ç”Ÿæˆï¼‰ï¼Œä¿å­˜æ–‡ä»¶å¹¶åªè¿”å›å…ƒæ•°æ®
        if actual_output_path:
            try:
                # éªŒè¯è¾“å‡ºè·¯å¾„å®‰å…¨æ€§
                if not validate_file_path(actual_output_path):
                    return {
                        "success": False,
                        "error": f"è¾“å‡ºè·¯å¾„ä¸åœ¨å…è®¸çš„ç›®å½•ä¸­: {actual_output_path}"
                    }
                
                output_file = Path(actual_output_path)
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                output_file.parent.mkdir(parents=True, exist_ok=True)
                
                # æ ¹æ®æ ¼å¼ä¿å­˜æ–‡ä»¶
                if result.output_format == "markdown":
                    # Markdownæ ¼å¼ç›´æ¥ä¿å­˜
                    output_file.write_text(result.content, encoding="utf-8")
                    logger.info(f"Markdownå†…å®¹å·²ä¿å­˜åˆ°: {actual_output_path}")
                    
                else:  # HTMLæ ¼å¼
                    # æ„å»ºå®Œæ•´çš„HTMLæ–‡æ¡£
                    html_parts = []
                    html_parts.append('<!DOCTYPE html>')
                    html_parts.append('<html lang="zh-CN">')
                    html_parts.append('<head>')
                    html_parts.append('    <meta charset="UTF-8">')
                    html_parts.append('    <meta name="viewport" content="width=device-width, initial-scale=1.0">')
                    html_parts.append(f'    <title>{Path(file_path).stem if file_path else "è¡¨æ ¼è§£æç»“æœ"}</title>')
                    html_parts.append('    <style>')
                    html_parts.append('        body { font-family: "Microsoft YaHei", Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }')
                    html_parts.append('        .container { max-width: 1400px; margin: 0 auto; background-color: white; padding: 30px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }')
                    html_parts.append('        h1 { color: #333; border-bottom: 3px solid #0066cc; padding-bottom: 10px; }')
                    html_parts.append('        .metadata { background-color: #f0f7ff; padding: 15px; border-radius: 5px; margin: 20px 0; }')
                    html_parts.append('        table { width: 100%; border-collapse: collapse; margin: 20px 0; font-size: 14px; }')
                    html_parts.append('        th, td { border: 1px solid #ddd; padding: 12px 8px; text-align: left; vertical-align: top; }')
                    html_parts.append('        th { background-color: #4a90e2; color: white; font-weight: bold; }')
                    html_parts.append('        tbody tr:nth-child(even) { background-color: #f9f9f9; }')
                    html_parts.append('        tbody tr:hover { background-color: #e8f4ff; }')
                    html_parts.append('        td[rowspan], td[colspan] { background-color: #fff3cd; font-weight: 500; }')
                    html_parts.append('    </style>')
                    html_parts.append('</head>')
                    html_parts.append('<body>')
                    html_parts.append('    <div class="container">')
                    html_parts.append(f'        <h1>{Path(file_path).stem if file_path else "è¡¨æ ¼è§£æç»“æœ"}</h1>')
                    
                    # æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
                    if result.metadata:
                        html_parts.append('        <div class="metadata">')
                        html_parts.append('            <h3>ğŸ“‹ æ–‡ä»¶ä¿¡æ¯</h3>')
                        html_parts.append('            <ul>')
                        html_parts.append(f'                <li><strong>å·¥ä½œè¡¨æ•°é‡ï¼š</strong>{result.metadata.get("sheets", 0)}ä¸ª</li>')
                        html_parts.append(f'                <li><strong>æ€»è¡Œæ•°ï¼š</strong>{result.metadata.get("total_rows", 0)}è¡Œ</li>')
                        html_parts.append(f'                <li><strong>æ€»åˆ—æ•°ï¼š</strong>{result.metadata.get("total_cols", 0)}åˆ—</li>')
                        if result.metadata.get("merged_cells_count"):
                            html_parts.append(f'                <li><strong>åˆå¹¶å•å…ƒæ ¼ï¼š</strong>{result.metadata["merged_cells_count"]}ä¸ª</li>')
                        if result.complexity_score:
                            html_parts.append(f'                <li><strong>å¤æ‚åº¦è¯„åˆ†ï¼š</strong>{result.complexity_score.total_score:.1f}/100ï¼ˆ{result.complexity_score.level}ï¼‰</li>')
                        html_parts.append('            </ul>')
                        html_parts.append('        </div>')
                    
                    # æ·»åŠ è¡¨æ ¼å†…å®¹
                    for i, table_html in enumerate(result.content, 1):
                        if len(result.content) > 1:
                            html_parts.append(f'        <h2>è¡¨æ ¼ {i}</h2>')
                        html_parts.append(f'        {table_html}')
                    
                    html_parts.append('    </div>')
                    html_parts.append('</body>')
                    html_parts.append('</html>')
                    
                    output_file.write_text('\n'.join(html_parts), encoding="utf-8")
                    logger.info(f"HTMLå†…å®¹å·²ä¿å­˜åˆ°: {actual_output_path}")
                
                # è¿”å›å…ƒæ•°æ®å’Œæ–‡ä»¶è·¯å¾„ï¼Œä¸è¿”å›å®Œæ•´å†…å®¹
                return {
                    "success": True,
                    "output_format": result.output_format,
                    "saved_to": str(actual_output_path),
                    "file_size": output_file.stat().st_size,
                    "complexity_score": result.complexity_score.to_dict() if result.complexity_score else None,
                    "metadata": result.metadata,
                    "message": f"âœ… æ–‡ä»¶å·²æˆåŠŸä¿å­˜åˆ° {actual_output_path}ï¼ˆ{output_file.stat().st_size / 1024:.1f} KBï¼‰",
                    "auto_generated": output_path is None  # æ ‡è®°æ˜¯å¦ä¸ºè‡ªåŠ¨ç”Ÿæˆçš„è·¯å¾„
                }
                
            except Exception as e:
                logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
                return {
                    "success": False,
                    "error": f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}"
                }
        
        # æ²¡æœ‰æä¾›è¾“å‡ºè·¯å¾„ï¼Œè¿”å›å®Œæ•´å†…å®¹
        return result.to_dict()
        
    except Exception as e:
        logger.error(f"è§£æå¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@mcp.tool()
def analyze_complexity(
    file_path: Optional[str] = None,
    file_content_base64: Optional[str] = None
) -> dict:
    """
    åˆ†æè¡¨æ ¼å¤æ‚åº¦ï¼ˆä¸ç”Ÿæˆè¾“å‡ºå†…å®¹ï¼Œä»…è¯„ä¼°ï¼‰
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        file_content_base64: Base64ç¼–ç çš„æ–‡ä»¶å†…å®¹
        
    Returns:
        å¤æ‚åº¦åˆ†æç»“æœå­—å…¸
    
    Examples:
        # åœ¨è§£æå‰å…ˆåˆ†æ
        analysis = analyze_complexity(file_path="/path/to/data.xlsx")
        if analysis["complexity_score"]["level"] == "complex":
            print("æ£€æµ‹åˆ°å¤æ‚è¡¨æ ¼ï¼Œæ¨èä½¿ç”¨HTMLæ ¼å¼")
    """
    try:
        # ç¡®å®šè¾“å…¥æº
        if file_path:
            # å®‰å…¨éªŒè¯
            if not validate_file_path(file_path):
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶è·¯å¾„ä¸åœ¨å…è®¸çš„ç›®å½•ä¸­: {file_path}"
                }
            
            input_data = file_path
            logger.info(f"åˆ†ææ–‡ä»¶å¤æ‚åº¦: {file_path}")
            
        elif file_content_base64:
            try:
                input_data = base64.b64decode(file_content_base64)
                logger.info(f"åˆ†æBase64å†…å®¹å¤æ‚åº¦ ({len(input_data)} bytes)")
            except Exception as e:
                return {
                    "success": False,
                    "error": f"Base64è§£ç å¤±è´¥: {e}"
                }
        else:
            return {
                "success": False,
                "error": "å¿…é¡»æä¾› file_path æˆ– file_content_base64"
            }
        
        # åˆ†æå¤æ‚åº¦
        score = parser.analyze_only(input_data)
        
        # ç”Ÿæˆå»ºè®®
        recommendation = generate_recommendation(score)
        
        return {
            "success": True,
            "complexity_score": score.to_dict(),
            "recommendation": recommendation
        }
        
    except Exception as e:
        logger.error(f"å¤æ‚åº¦åˆ†æå¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@mcp.tool()
def batch_parse(
    file_paths: list[str],
    output_format: str = "auto",
    output_dir: str = "./output",
    max_workers: int = 4
) -> dict:
    """
    æ‰¹é‡è§£æå¤šä¸ªè¡¨æ ¼æ–‡ä»¶
    
    Args:
        file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_format: è¾“å‡ºæ ¼å¼ (auto/markdown/html)
        output_dir: è¾“å‡ºç›®å½•
        max_workers: æœ€å¤§å¹¶å‘æ•°
        
    Returns:
        æ‰¹é‡å¤„ç†ç»“æœå­—å…¸
    
    Examples:
        result = batch_parse(
            file_paths=[
                "/data/report1.xlsx",
                "/data/report2.csv",
                "/data/table3.xlsx"
            ],
            output_format="auto",
            output_dir="./parsed_tables"
        )
    """
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        results = []
        succeeded = 0
        failed = 0
        
        def process_file(file_path):
            try:
                # å®‰å…¨éªŒè¯
                if not validate_file_path(file_path):
                    return {
                        "file": file_path,
                        "status": "failed",
                        "error": "æ–‡ä»¶è·¯å¾„ä¸åœ¨å…è®¸çš„ç›®å½•ä¸­"
                    }
                
                # è§£ææ–‡ä»¶ï¼ˆé»˜è®¤æå–å›¾ç‰‡ï¼‰
                result = parser.parse(
                    file_path, 
                    output_format=output_format,
                    extract_images=True
                )
                
                if not result.success:
                    return {
                        "file": file_path,
                        "status": "failed",
                        "error": result.error
                    }
                
                # ä¿å­˜è¾“å‡º
                file_stem = Path(file_path).stem
                if result.output_format == "markdown":
                    output_file = output_path / f"{file_stem}.md"
                    output_file.write_text(result.content, encoding='utf-8')
                else:  # HTML
                    output_file = output_path / f"{file_stem}.html"
                    output_file.write_text("\n\n".join(result.content), encoding='utf-8')
                
                return {
                    "file": file_path,
                    "status": "success",
                    "output_file": str(output_file),
                    "complexity_level": result.complexity_score.level if result.complexity_score else "unknown"
                }
                
            except Exception as e:
                return {
                    "file": file_path,
                    "status": "failed",
                    "error": str(e)
                }
        
        # å¹¶è¡Œå¤„ç†
        logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶ï¼Œå¹¶å‘æ•°: {max_workers}")
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(process_file, fp): fp for fp in file_paths}
            
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
                
                if result["status"] == "success":
                    succeeded += 1
                else:
                    failed += 1
        
        logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸ {succeeded}, å¤±è´¥ {failed}")
        
        return {
            "success": True,
            "total": len(file_paths),
            "succeeded": succeeded,
            "failed": failed,
            "results": results
        }
        
    except Exception as e:
        logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@mcp.tool()
def get_preview(
    file_path: Optional[str] = None,
    file_content_base64: Optional[str] = None,
    max_rows: int = 10,
    max_cols: int = 10
) -> dict:
    """
    é¢„è§ˆè¡¨æ ¼å†…å®¹ï¼ˆä¸å®Œæ•´è§£æï¼Œå¿«é€Ÿè¿”å›ï¼‰
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        file_content_base64: Base64ç¼–ç çš„æ–‡ä»¶å†…å®¹
        max_rows: æœ€å¤§é¢„è§ˆè¡Œæ•°
        max_cols: æœ€å¤§é¢„è§ˆåˆ—æ•°
        
    Returns:
        é¢„è§ˆä¿¡æ¯å­—å…¸
    
    Examples:
        # å¿«é€Ÿé¢„è§ˆæ–‡ä»¶å†…å®¹
        preview = get_preview(
            file_path="/path/to/data.xlsx",
            max_rows=5
        )
        print(f"æ–‡ä»¶åŒ…å« {preview['metadata']['sheets_count']} ä¸ªsheet")
        for sheet in preview['sheets']:
            print(f"Sheet: {sheet['name']}, è¡Œæ•°: {sheet['total_rows']}")
    """
    try:
        # ç¡®å®šè¾“å…¥æº
        if file_path:
            # å®‰å…¨éªŒè¯
            if not validate_file_path(file_path):
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶è·¯å¾„ä¸åœ¨å…è®¸çš„ç›®å½•ä¸­: {file_path}"
                }
            
            input_data = file_path
            logger.info(f"é¢„è§ˆæ–‡ä»¶: {file_path}")
            
        elif file_content_base64:
            try:
                input_data = base64.b64decode(file_content_base64)
                logger.info(f"é¢„è§ˆBase64å†…å®¹ ({len(input_data)} bytes)")
            except Exception as e:
                return {
                    "success": False,
                    "error": f"Base64è§£ç å¤±è´¥: {e}"
                }
        else:
            return {
                "success": False,
                "error": "å¿…é¡»æä¾› file_path æˆ– file_content_base64"
            }
        
        # é¢„è§ˆ
        result = parser.preview(
            input_data,
            max_rows=max_rows,
            max_cols=max_cols
        )
        
        return result
        
    except Exception as e:
        logger.error(f"é¢„è§ˆå¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


if __name__ == "__main__":
    # å¯åŠ¨MCPæœåŠ¡å™¨
    logger.info("ğŸš€ å¯åŠ¨TableParser MCPæœåŠ¡å™¨...")
    mcp.run(transport="stdio")  # ä½¿ç”¨æ ‡å‡†è¾“å…¥è¾“å‡ºï¼ˆæ¨èï¼‰
    # æˆ–è€…ä½¿ç”¨HTTP
    # mcp.run(transport="http", host="0.0.0.0", port=8765)

